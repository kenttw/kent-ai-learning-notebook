{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/kent/git/courses/python_ML2/session4_kaggle/house_prices_advanced_regression_techniques/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000   \n",
       "\n",
       "           ...         WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count      ...        1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean       ...          94.244521    46.660274      21.954110     3.409589   \n",
       "std        ...         125.338794    66.256028      61.119149    29.317331   \n",
       "min        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "25%        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "50%        ...           0.000000    25.000000       0.000000     0.000000   \n",
       "75%        ...         168.000000    68.000000       0.000000     0.000000   \n",
       "max        ...         857.000000   547.000000     552.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean     15.060959     2.758904     43.489041     6.321918  2007.815753   \n",
       "std      55.757415    40.177307    496.123024     2.703626     1.328095   \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000   \n",
       "25%       0.000000     0.000000      0.000000     5.000000  2007.000000   \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000   \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000   \n",
       "max     480.000000   738.000000  15500.000000    12.000000  2010.000000   \n",
       "\n",
       "           SalePrice  \n",
       "count    1460.000000  \n",
       "mean   180921.195890  \n",
       "std     79442.502883  \n",
       "min     34900.000000  \n",
       "25%    129975.000000  \n",
       "50%    163000.000000  \n",
       "75%    214000.000000  \n",
       "max    755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Id\n",
    "train = train.drop('Id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.drop(['MiscVal'], axis = 1, inplace = True)\n",
    "#1. Convert NA into 'No' Categorical values\n",
    "meaningfulNA = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu', \n",
    " 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "train[meaningfulNA] = train[meaningfulNA].fillna('No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do shuffle\n",
    "train = train.sample(frac=1,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intVar => ['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice'] \n",
      "\n",
      "floatVar => ['LotFrontage', 'MasVnrArea', 'GarageYrBlt'] \n",
      "\n",
      "objectVar => ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "intVar = train.select_dtypes(include = ['int']).columns.tolist()\n",
    "floatVar = train.select_dtypes(include = ['float']).columns.tolist()\n",
    "objectVar = train.select_dtypes(include = ['object']).columns.tolist()\n",
    "\n",
    "\n",
    "print(\"intVar =>\",intVar,\"\\n\")\n",
    "print(\"floatVar =>\",floatVar,\"\\n\")\n",
    "print(\"objectVar =>\",objectVar,\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 進行資料編碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['RL', 'Pave', 'No', ..., 'No', 'WD', 'Normal'],\n",
       "       ['RL', 'Pave', 'No', ..., 'No', 'WD', 'Normal'],\n",
       "       ['RL', 'Pave', 'No', ..., 'No', 'WD', 'Normal'],\n",
       "       ..., \n",
       "       ['RM', 'Pave', 'No', ..., 'No', 'WD', 'Normal'],\n",
       "       ['RM', 'Pave', 'No', ..., 'No', 'WD', 'Normal'],\n",
       "       ['C (all)', 'Grvl', 'No', ..., 'Shed', 'ConLD', 'Normal']], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cate_data = train[objectVar]\n",
    "cate_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "Xstr = cate_data.values.astype(dtype=\"str\")\n",
    "# transform to integer\n",
    "Xint = LabelEncoder().fit_transform(Xstr.ravel()).reshape(*Xstr.shape)\n",
    "# transform to binary\n",
    "Xbin = OneHotEncoder().fit_transform(Xint).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cate = Xbin\n",
    "X_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 3)\n",
      "(1460, 33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stds = StandardScaler()\n",
    "X_float = train[floatVar]\n",
    "X_int = train[intVar[:-1]]\n",
    "\n",
    "print(X_float.shape)\n",
    "print(X_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 36)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_real = np.column_stack((X_float,X_int))\n",
    "X_real = np.nan_to_num(X_real)\n",
    "\n",
    "X_real_scaled = stds.fit_transform(X_real)\n",
    "X_real_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 303)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = np.column_stack((X_real_scaled,X_cate))\n",
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10dc04b38>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvgAAAHxCAYAAAAYxci2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1104a3d30>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 380
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=290,whiten=True)\n",
    "X_train_pca = pca.fit_transform(X_all)\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.63688999],\n",
       "       [-0.01789575],\n",
       "       [-0.74193766],\n",
       "       ..., \n",
       "       [-0.67897749],\n",
       "       [-1.15117874],\n",
       "       [-1.25821103]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = train['SalePrice']\n",
    "\n",
    "stds_y = StandardScaler()\n",
    "Y_scaled = stds_y.fit_transform(Y.reshape(-1, 1))\n",
    "Y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15620.960568981267"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression,SGDRegressor,BayesianRidge\n",
    "from sklearn import metrics\n",
    "lr = SGDRegressor(loss='squared_loss', \n",
    "                  penalty='l1', alpha=0.005, l1_ratio=0.15, \n",
    "                  fit_intercept=True, max_iter=None, tol=None, \n",
    "                  shuffle=True, verbose=0, epsilon=0.1, random_state=1, learning_rate='invscaling', \n",
    "                  eta0=0.01, power_t=0.25, warm_start=False, average=False, n_iter=None)\n",
    "\n",
    "\n",
    "# lr = BayesianRidge(n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, \n",
    "#                    lambda_2=1e-06, compute_score=False, fit_intercept=True, normalize=True, \n",
    "#                    copy_X=True, verbose=False)\n",
    "\n",
    "lr.fit(X_train_pca[:-100],Y_scaled[:-100])\n",
    "\n",
    "\n",
    "# 拿 training 直接驗證\n",
    "predict_y = lr.predict(X_train_pca[-100:])\n",
    "metrics.mean_absolute_error(Y[-100:],stds_y.inverse_transform(predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.53942745e-01,  -4.79872570e-03,   1.10518411e-01,\n",
       "        -2.36182530e-02,   1.41862709e-02,  -1.17714132e-01,\n",
       "         5.91569627e-02,  -4.12053500e-02,  -5.45724911e-03,\n",
       "         6.34045981e-02,   2.62153120e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,  -2.60594151e-02,  -2.49264654e-02,\n",
       "        -1.34383939e-02,   3.02888081e-02,  -1.13434480e-02,\n",
       "        -3.40987194e-02,   2.99929429e-02,  -2.93259797e-02,\n",
       "         1.82615167e-02,  -3.13837929e-02,   0.00000000e+00,\n",
       "         4.99455550e-02,   8.64455224e-02,  -8.69678855e-02,\n",
       "         2.29083204e-02,   1.06108895e-02,  -2.43781943e-02,\n",
       "        -4.52177986e-02,  -4.57642209e-02,  -2.09299464e-02,\n",
       "        -6.43498484e-02,  -2.14623495e-02,   8.61508045e-04,\n",
       "         6.71083333e-03,   2.99307236e-02,   3.18029928e-03,\n",
       "         0.00000000e+00,  -2.80891155e-02,  -3.96399501e-02,\n",
       "         3.25534629e-02,  -6.41809254e-03,   0.00000000e+00,\n",
       "        -3.25871918e-02,   0.00000000e+00,   7.71294754e-03,\n",
       "         2.84984668e-02,   0.00000000e+00,  -2.02048667e-02,\n",
       "        -2.27502041e-02,   3.97525433e-02,   4.49031109e-03,\n",
       "         0.00000000e+00,  -3.31768777e-02,  -3.66230128e-03,\n",
       "         3.44419030e-02,  -3.64793167e-02,  -9.33276719e-03,\n",
       "         2.68871785e-02,  -1.48470233e-02,  -2.50713797e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.10301805e-02,\n",
       "        -1.57860382e-02,  -3.08282737e-02,   4.40019670e-02,\n",
       "         2.09369449e-02,   0.00000000e+00,   2.05193051e-02,\n",
       "        -1.42108283e-02,   4.37294850e-02,  -1.57645538e-02,\n",
       "         0.00000000e+00,  -3.87099653e-02,  -1.95564205e-02,\n",
       "         0.00000000e+00,   1.40232096e-02,  -2.96962654e-02,\n",
       "        -1.63433453e-02,  -5.26335415e-02,  -3.12013746e-02,\n",
       "         6.98051689e-03,  -1.65712878e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.76815121e-02,   2.00905578e-02,\n",
       "        -1.87450866e-02,  -2.61286198e-02,   1.93939658e-02,\n",
       "         1.09264248e-02,   0.00000000e+00,  -5.87573191e-03,\n",
       "        -2.98600010e-02,   8.07610126e-03,   1.42260870e-02,\n",
       "         0.00000000e+00,   1.10217899e-02,   0.00000000e+00,\n",
       "         7.84637737e-03,   1.86778751e-02,  -1.37033091e-02,\n",
       "        -1.24431143e-02,   1.40510971e-03,  -1.53697865e-02,\n",
       "         1.57308509e-02,   6.96048041e-03,   0.00000000e+00,\n",
       "        -1.15777449e-02,  -2.33657792e-02,  -1.64566736e-02,\n",
       "         1.55641094e-02,   0.00000000e+00,  -2.46020184e-02,\n",
       "        -1.51487552e-02,  -2.46606696e-02,   1.58953403e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   4.30249631e-02,\n",
       "        -2.90220109e-02,   0.00000000e+00,  -3.62312800e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   8.57261867e-03,\n",
       "        -1.56312521e-02,   0.00000000e+00,  -2.29976850e-02,\n",
       "         4.26800511e-02,   2.26158128e-02,   5.53330606e-02,\n",
       "         0.00000000e+00,  -6.67741058e-03,  -4.13704913e-03,\n",
       "        -3.59076892e-03,   2.02057358e-02,  -8.24413279e-03,\n",
       "        -5.29562838e-03,   1.64712980e-02,  -8.75735013e-03,\n",
       "         0.00000000e+00,  -1.96780155e-02,  -2.19269884e-02,\n",
       "        -1.08485874e-02,  -3.25861184e-02,  -1.15410765e-02,\n",
       "         0.00000000e+00,  -1.55483602e-02,   2.62452787e-03,\n",
       "        -1.33055853e-02,   6.65763199e-03,   2.22395353e-02,\n",
       "        -9.76287971e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,  -2.86298233e-02,   0.00000000e+00,\n",
       "         1.51905932e-02,   1.15297232e-03,  -2.73322666e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -1.41788863e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "         2.19782082e-02,   0.00000000e+00,  -2.29725996e-02,\n",
       "         4.15357616e-03,  -2.14443749e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,  -2.12450755e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,  -1.16731931e-02,   3.45588215e-03,\n",
       "         0.00000000e+00,   8.39120296e-03,   1.45392138e-02,\n",
       "        -1.23504923e-02,   6.80936638e-03,   0.00000000e+00,\n",
       "        -1.39643167e-03,   6.41192142e-03,  -7.25249338e-03,\n",
       "         0.00000000e+00,   1.20473502e-02,   6.95261869e-03,\n",
       "         0.00000000e+00,  -2.12829082e-02,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.06330575e-02,   0.00000000e+00,\n",
       "         2.74631890e-02,   3.11550154e-03,   0.00000000e+00,\n",
       "         7.74105527e-03,   0.00000000e+00,   1.74986238e-02,\n",
       "        -7.52580226e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "        -2.21420643e-03,   0.00000000e+00,  -2.84764433e-02,\n",
       "         1.03189429e-02,   2.18968111e-03,   0.00000000e+00,\n",
       "        -5.19965981e-02,   2.00866240e-02,  -7.32627811e-02,\n",
       "        -1.51553378e-02,   0.00000000e+00,  -7.06072408e-02,\n",
       "        -3.55231034e-02,   4.24415450e-03,   0.00000000e+00,\n",
       "         5.44206214e-02,  -1.06051684e-02,  -1.92696757e-02,\n",
       "         7.46431037e-03,  -1.16778504e-02,   1.44614237e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,  -1.02681535e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   2.57910892e-02,  -7.92994875e-03,\n",
       "        -1.36525509e-02,   6.86177006e-02,   1.16062473e-02,\n",
       "         0.00000000e+00,  -3.87761169e-03,  -6.31699961e-02,\n",
       "         3.11723654e-03,   6.49369345e-02,   2.64931235e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         5.51843969e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "        -1.79039103e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   3.42556104e-03,  -5.36642565e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "        -1.31525447e-02,   0.00000000e+00,  -1.20651405e-02,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,  -6.51260133e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,  -5.62573290e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.70413784e-03,\n",
       "        -5.08404178e-04,   0.00000000e+00,   8.93421025e-03,\n",
       "         6.95690843e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.27301764],\n",
       "       [ 0.20080544],\n",
       "       [ 0.12095542],\n",
       "       ..., \n",
       "       [ 0.1278989 ],\n",
       "       [ 0.0758228 ],\n",
       "       [ 0.06401889]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "Y = train['SalePrice']\n",
    "stds_y = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "Y_scaled = stds_y.fit_transform(Y.reshape(-1, 1))\n",
    "Y_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = Input(shape=(X_all.shape[1],))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = Dense(32,activation='linear',\n",
    "               kernel_regularizer=regularizers.l1(0.005),)(input_x)\n",
    "\n",
    "output = Dense(1,activation='linear',\n",
    "               kernel_regularizer=regularizers.l1(0.005),)(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_x,output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 303)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 304       \n",
      "=================================================================\n",
      "Total params: 304\n",
      "Trainable params: 304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adagrad(),\n",
    "              loss='mean_squared_error',)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "error = model.fit(X_all[100:],Y_scaled[100:],\n",
    "                  batch_size=8,validation_split=0.10,\n",
    "                  validation_steps=None,epochs=200,verbose=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0034044893105435216,\n",
       " 0.0034117088592276463,\n",
       " 0.0034223971454718826,\n",
       " 0.0034034259128840824,\n",
       " 0.0034023357868754591,\n",
       " 0.003379752280440157,\n",
       " 0.0033988516307527235,\n",
       " 0.0033775091436052439,\n",
       " 0.0033878986906333299,\n",
       " 0.0033966011879052603,\n",
       " 0.0033971481185004699,\n",
       " 0.003376261454404277,\n",
       " 0.0033770276193987895,\n",
       " 0.0033916904213625232,\n",
       " 0.0033724791525552669,\n",
       " 0.0033835608609556374,\n",
       " 0.003388825831386973,\n",
       " 0.0033867772915126648,\n",
       " 0.0033632195280755266,\n",
       " 0.0033869824115053014,\n",
       " 0.0033810748399107481,\n",
       " 0.0033738304940021894,\n",
       " 0.003378499906473592,\n",
       " 0.0033837191492708681,\n",
       " 0.0033723726165572217,\n",
       " 0.0033658824654089082,\n",
       " 0.0033718091877043442,\n",
       " 0.0033667264498611973,\n",
       " 0.003398473697921468,\n",
       " 0.0033623425920000847,\n",
       " 0.0033784987917778635,\n",
       " 0.0033718075814772566,\n",
       " 0.0033714244776752358,\n",
       " 0.0033680660965140254,\n",
       " 0.0033700612215386105,\n",
       " 0.0033676241451472627,\n",
       " 0.0033702658248907016,\n",
       " 0.0033526686575641139,\n",
       " 0.0033606791882501807,\n",
       " 0.0033634670468327267,\n",
       " 0.0033690750726736059,\n",
       " 0.0033676419163646263,\n",
       " 0.0033523320886945608,\n",
       " 0.0033665361747243047,\n",
       " 0.0033541039443495714,\n",
       " 0.0033584329059189247,\n",
       " 0.0033649222505297148,\n",
       " 0.0033395376864492018,\n",
       " 0.0033629465006669267,\n",
       " 0.0033753990360042628,\n",
       " 0.0033523652754310104,\n",
       " 0.003355110392850988,\n",
       " 0.0033484518176456002,\n",
       " 0.0033514805068109743,\n",
       " 0.0033450665384579716,\n",
       " 0.0033608553162623755,\n",
       " 0.0033571816976273468,\n",
       " 0.0033559978892418003,\n",
       " 0.0033540732662491746,\n",
       " 0.0033606158522280312,\n",
       " 0.0033511021897330686,\n",
       " 0.0033522123178722813,\n",
       " 0.0033478336446778546,\n",
       " 0.0033597551435353905,\n",
       " 0.0033581899334463516,\n",
       " 0.0033443974836248587,\n",
       " 0.0033470790321920431,\n",
       " 0.0033642382115990021,\n",
       " 0.0033509576635350003,\n",
       " 0.0033486088132181394,\n",
       " 0.0033571263486093361,\n",
       " 0.0033380026674945077,\n",
       " 0.0033369751158626934,\n",
       " 0.0033564934768756621,\n",
       " 0.0033364074618184294,\n",
       " 0.0033433539876592607,\n",
       " 0.003356876124147009,\n",
       " 0.0033413455091124656,\n",
       " 0.0033443838173791377,\n",
       " 0.0033428839885696672,\n",
       " 0.0033523315644451704,\n",
       " 0.0033474053192299371,\n",
       " 0.0033544098335969584,\n",
       " 0.003349738686308995,\n",
       " 0.003347672801312619,\n",
       " 0.0033525578842005309,\n",
       " 0.0033441226437894832,\n",
       " 0.0033503246586465466,\n",
       " 0.0033515947711124433,\n",
       " 0.0033536940711106056,\n",
       " 0.0033394379459102362,\n",
       " 0.0033413378059182291,\n",
       " 0.0033518076871272202,\n",
       " 0.0033520740042957994,\n",
       " 0.0033478259962672987,\n",
       " 0.0033420852105455852,\n",
       " 0.0033406968870705444,\n",
       " 0.003345523407725386,\n",
       " 0.0033493410868971956,\n",
       " 0.003320739622033061,\n",
       " 0.003344293320825433,\n",
       " 0.0033348834414485525,\n",
       " 0.0033476903693738327,\n",
       " 0.0033215241349953549,\n",
       " 0.003344281527116359,\n",
       " 0.0033414001687691588,\n",
       " 0.003350371842613456,\n",
       " 0.0033373890187457398,\n",
       " 0.0033530368609658253,\n",
       " 0.0033345541565259007,\n",
       " 0.0033530140937811214,\n",
       " 0.0033449775941085582,\n",
       " 0.0033405442894101629,\n",
       " 0.0033338643927005381,\n",
       " 0.0033461117608704015,\n",
       " 0.003343581550699823,\n",
       " 0.0033319240779877681,\n",
       " 0.0033468813323446252,\n",
       " 0.0033300539114956861,\n",
       " 0.0033473797337292065,\n",
       " 0.0033454346688147757,\n",
       " 0.0033363100062154868,\n",
       " 0.0033417927988445739,\n",
       " 0.0033485798189550444,\n",
       " 0.0033350327749146159,\n",
       " 0.0033383392340814075,\n",
       " 0.0033420075455473531,\n",
       " 0.0033415361372997462,\n",
       " 0.0033529013854883662,\n",
       " 0.0033379091403380134,\n",
       " 0.0033435602581091957,\n",
       " 0.0033315155872758601,\n",
       " 0.0033392977293617292,\n",
       " 0.0033442539024452853,\n",
       " 0.0033428707035270586,\n",
       " 0.0033376487063280507,\n",
       " 0.0033285945092382677,\n",
       " 0.0033415717748450299,\n",
       " 0.0033275086525523293,\n",
       " 0.0033401955174756984,\n",
       " 0.003340981623730044,\n",
       " 0.0033381563920247691,\n",
       " 0.0033391525305418016,\n",
       " 0.0033411336157263983,\n",
       " 0.0033309321174872855,\n",
       " 0.0033414463141287851,\n",
       " 0.0033324323731529363,\n",
       " 0.0033225012065087951,\n",
       " 0.0033345954459209261,\n",
       " 0.0033425016525000626,\n",
       " 0.0033376694092332247,\n",
       " 0.0033381194518452961,\n",
       " 0.003336460971778709,\n",
       " 0.0033421951956328711,\n",
       " 0.0033232725546482244,\n",
       " 0.0033433966108847384,\n",
       " 0.0033456431024592201,\n",
       " 0.0033342989482703844,\n",
       " 0.0033318039046576113,\n",
       " 0.0033456013124022218,\n",
       " 0.0033358733909314171,\n",
       " 0.0033324115812242809,\n",
       " 0.0033405895270346331,\n",
       " 0.0033371918636915924,\n",
       " 0.0033354244447538471,\n",
       " 0.0033400786136660505,\n",
       " 0.0033376757565313597,\n",
       " 0.003346107258717073,\n",
       " 0.003322305782466786,\n",
       " 0.0033270317880022856,\n",
       " 0.0033424267122290686,\n",
       " 0.0033433333425813058,\n",
       " 0.0033296962280824683,\n",
       " 0.0033336813482486346,\n",
       " 0.0033345538118452417,\n",
       " 0.0033396010582329204,\n",
       " 0.0033363112152608879,\n",
       " 0.0033364806345548312,\n",
       " 0.0033322306337699391,\n",
       " 0.0033281833767355266,\n",
       " 0.0033252566438046545,\n",
       " 0.0033405477080640255,\n",
       " 0.0033351222085127351,\n",
       " 0.0033285075310142895,\n",
       " 0.0033369463209513258,\n",
       " 0.0033345764230486323,\n",
       " 0.0033407190714177548,\n",
       " 0.0033210514545489369,\n",
       " 0.0033352495120911332,\n",
       " 0.0033268201030985591,\n",
       " 0.0033233902999960812,\n",
       " 0.0033360456270196178,\n",
       " 0.0033356119807066969,\n",
       " 0.0033290223941340848,\n",
       " 0.0033351505765679226,\n",
       " 0.0033403093351379912,\n",
       " 0.0033342155127244351,\n",
       " 0.0033285935406323548,\n",
       " 0.0033354386938370616,\n",
       " 0.0033406555223479575]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18079.386552734373"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拿 training 直接驗證\n",
    "predict_y = model.predict(X_all[:100])\n",
    "metrics.mean_absolute_error(Y[:100], stds_y.inverse_transform(predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
